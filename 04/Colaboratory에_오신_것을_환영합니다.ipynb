{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ResNet 기본 블록 정의\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3):\n",
        "        super(BasicBlock, self).__init__()\n",
        "\n",
        "        # 합성곱층 정의 Conv2d 레이어\n",
        "        # 입력과 출력의 크기를 맞추기 위해서 커널이 3일 때 패딩 1, 스트라이드 1 필요. stride 기본값은 1\n",
        "        self.c1 = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=1)\n",
        "        self.c2 = nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, padding=1)\n",
        "\n",
        "        # 스킵 커넥션할 입력의 크기 유지 + 출력 채널 수 변경 위해서 커널 값 1을 적용한 층\n",
        "        self.downsample = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "        #배치 정규화층 정의\n",
        "        self.bn1 = nn.BatchNorm2d(num_features=out_channels)\n",
        "        self.bn2 = nn.BatchNorm2d(num_features=out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    # Conv → BN → ReLU → Conv → BN 구조\n",
        "    def forward(self, x):\n",
        "        # 스킵 커넥션할 x_\n",
        "        x_ = x\n",
        "\n",
        "        # x 필터 통과\n",
        "        x = self.c1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.c2(x)\n",
        "        x = self.bn2(x)\n",
        "\n",
        "        # 합성곱의 결과와 입력의 채널 수를 맞춤(채널 수 늘어남)\n",
        "        x_ = self.downsample(x_)\n",
        "\n",
        "        #합성곱층의 결과(특징 맵)와 저장해놨던 입력값을 더해줌\n",
        "        x += x_\n",
        "        x = self.relu(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "ekKE0wKDQpz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet 모델 정의하기\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, num_classes=10): # 분류할 클래스의 수가 10\n",
        "        super(ResNet, self).__init__()\n",
        "\n",
        "        # 기본 블록\n",
        "        self.b1 = BasicBlock(in_channels=3, out_channels=64)\n",
        "        self.b2 = BasicBlock(in_channels=64, out_channels=128)\n",
        "        self.b3 = BasicBlock(in_channels=128, out_channels=256)\n",
        "        # 풀링을 최댓값이 아닌 평균값으로\n",
        "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        # fully connected layer(MLP)\n",
        "        # (생각해보기) 왜 4096일까?\n",
        "        self.fc1 = nn.Linear(in_features=4096, out_features=2048)\n",
        "        self.fc2 = nn.Linear(in_features=2048, out_features=512)\n",
        "        self.fc3 = nn.Linear(in_features=512, out_features=num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 기본 블록과 풀링층을 통과 = 전체 특징 추출 파트\n",
        "        # 블록 수 계속 늘려보기\n",
        "        x = self.b1(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.b2(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.b3(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # 분류기의 입력으로 사용하기 위해 flatten\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "\n",
        "        # 분류기로 예측값 출력: 최종 출력 생성\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "sNcrpSIIS-O7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 전처리부\n",
        "\n",
        "import tqdm\n",
        "\n",
        "from torchvision.datasets.cifar import CIFAR10\n",
        "from torchvision.transforms import Compose, ToTensor\n",
        "from torchvision.transforms import RandomHorizontalFlip, RandomCrop\n",
        "from torchvision.transforms import Normalize\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "from torch.optim.adam import Adam\n",
        "\n",
        "train_transforms = Compose([\n",
        "   RandomCrop((32, 32), padding=4),  #주변에 4픽셀 추가한 후, 32*32 크기로 랜덤 크롭핑\n",
        "   RandomHorizontalFlip(p=0.5),  #50% 확률로 y축으로 뒤집기\n",
        "   ToTensor(),  #텐서로 변환(픽셀값 범위를 정규화함)\n",
        "   #이미지 정규화(R, G, B 각 채널별)\n",
        "   Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261))\n",
        "])\n",
        "\n",
        "test_transform = Compose([\n",
        "    ToTensor(),\n",
        "    Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261))\n",
        "])"
      ],
      "metadata": {
        "id": "U_2Ns6nogkiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#학습 데이터와 평가 데이터 불러오기\n",
        "#transform = transforms 사용하면서 데이터의 증강이 적용됨.\n",
        "#실제 저장공간에서의 데이터 수가 늘어나나? no. 하지만 매 epoch에서 랜덤한 변화가 생기면서 다양한 모습의 데이터를 볼 수 있음.\n",
        "training_data = CIFAR10(root=\"./\", train=True, download=True, transform=train_transforms)\n",
        "\n",
        "#test데이터는 평가용이므로, 원본 데이터로 측정해야 함.\n",
        "test_data = CIFAR10(root=\"./\", train=False, download=True, transform=test_transform)\n",
        "\n",
        "train_loader = DataLoader(training_data, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "qAboBIATgn1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = ResNet(num_classes=10)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "H8cqAchkgqTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-4\n",
        "optim = Adam(model.parameters(), lr=lr)\n",
        "\n",
        "for epoch in range(1):#시간관계상 1, 작동 테스트 후 큰 값으로 변경 바람\n",
        "   iterator = tqdm.tqdm(train_loader)\n",
        "   for data, label in iterator:\n",
        "       # 최적화를 위해 기울기를 초기화\n",
        "       optim.zero_grad()\n",
        "\n",
        "       # 모델의 예측값\n",
        "       preds = model(data.to(device))\n",
        "\n",
        "       # 손실 계산 및 역전파\n",
        "       loss = nn.CrossEntropyLoss()(preds, label.to(device))\n",
        "       loss.backward()\n",
        "       optim.step()\n",
        "\n",
        "       iterator.set_description(f\"epoch:{epoch+1} loss:{loss.item()}\")\n",
        "\n",
        "torch.save(model.state_dict(), \"ResNet.pth\")"
      ],
      "metadata": {
        "id": "mv_tuOn-gsu7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Colaboratory에 오신 것을 환영합니다",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}